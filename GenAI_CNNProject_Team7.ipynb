{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52016/GEN-AI/blob/main/GenAI_CNNProject_Team7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLMyYmosihBh"
      },
      "source": [
        "#**Importing tensorflow package**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjzH-eqWH0Q2"
      },
      "outputs": [],
      "source": [
        ";import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5Sxi74wJomY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fJct3cqio5e"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#**Mounting Drive and Creating directories for the Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVkuPJk1JwEl",
        "outputId": "f3e509b1-b8dd-43a5-e814-7c8992e068a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTDu0LZjJ0NO",
        "outputId": "55415a63-fd4a-4e5a-ea4a-a1c7650c4d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/DogEmotions/Images/training_set'  # Path to the training dataset\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    shear_range=0.2,  # Apply random shear transformation\n",
        "    zoom_range=0.2,  # Apply random zoom\n",
        "    horizontal_flip=True  # Randomly flip images horizontally\n",
        ")\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    data_dir,  # Directory containing class-wise image folders\n",
        "    target_size=(64, 64),  # Resize all images to 64x64 pixels\n",
        "    batch_size=32,  # Number of images per batch\n",
        "    class_mode='categorical'  # Use binary labels (0 or 1) for two classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BPHVDMPJ72n",
        "outputId": "1f2ef156-4f2d-4fa2-dd0b-d9a8c7951e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dir = '/content/drive/MyDrive/DogEmotions/Images/test_set'  # Path to the test dataset\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Only normalize, no augmentation for test data\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    test_dir,  # Directory containing test images in class-wise folders\n",
        "    target_size=(64, 64),  # Resize all images to 64x64 pixels\n",
        "    batch_size=32,  # Number of images per batch\n",
        "    class_mode='categorical'  # Binary classification (0 or 1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nLU8zgDiyYO"
      },
      "source": [
        "#**Building the CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGh86-Ha_q-2"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JLxcEisShdf"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Input(shape=(64, 64, 3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9MX_mRqjEcF"
      },
      "source": [
        "###**Adding 1st convolution layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0UPjUoA4xJU"
      },
      "outputs": [],
      "source": [
        "#Step 1: Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy2nAvvE6FE2"
      },
      "outputs": [],
      "source": [
        "#Step 2: Pooling or Max Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLMUV2fjN99"
      },
      "source": [
        "###**Adding Convolution Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcx9HqpY66Ft"
      },
      "outputs": [],
      "source": [
        "#Adding another convulation layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZhxpkWV7FMA"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VogUIo7jVrD"
      },
      "source": [
        "###**Adding Convolution Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gDLk_0xVCkQ"
      },
      "outputs": [],
      "source": [
        "#Adding another convulation layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwig2esyVE7T"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyAGD-Z9jdsb"
      },
      "source": [
        "###**Flattening, full connection and adding a output layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_RRwN_G7I99"
      },
      "outputs": [],
      "source": [
        "#Step 3: Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-SoE-Qh7p_u"
      },
      "outputs": [],
      "source": [
        "#Step 4: Full connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQkf3Mrg8Hst"
      },
      "outputs": [],
      "source": [
        "#Output-Layer\n",
        "cnn.add(tf.keras.layers.Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTZSspPwju2Y"
      },
      "source": [
        "###**Compiling and fitting the value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZZRonnj8V_B"
      },
      "outputs": [],
      "source": [
        "#Compiling the cnn\n",
        "cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Changed loss function\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVGZpla59TbK",
        "outputId": "e3ffc39b-dcbc-4c6e-d24e-3cf4ddb5f743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1127s\u001b[0m 9s/step - accuracy: 0.2581 - loss: 1.3895 - val_accuracy: 0.2625 - val_loss: 1.3831\n",
            "Epoch 2/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 412ms/step - accuracy: 0.2841 - loss: 1.3824 - val_accuracy: 0.2488 - val_loss: 1.3837\n",
            "Epoch 3/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 398ms/step - accuracy: 0.2764 - loss: 1.3823 - val_accuracy: 0.3050 - val_loss: 1.3725\n",
            "Epoch 4/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 405ms/step - accuracy: 0.3041 - loss: 1.3708 - val_accuracy: 0.3212 - val_loss: 1.3679\n",
            "Epoch 5/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 404ms/step - accuracy: 0.3131 - loss: 1.3600 - val_accuracy: 0.3000 - val_loss: 1.3595\n",
            "Epoch 6/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 390ms/step - accuracy: 0.3268 - loss: 1.3557 - val_accuracy: 0.3050 - val_loss: 1.3759\n",
            "Epoch 7/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 402ms/step - accuracy: 0.3372 - loss: 1.3438 - val_accuracy: 0.3088 - val_loss: 1.3803\n",
            "Epoch 8/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 396ms/step - accuracy: 0.3524 - loss: 1.3272 - val_accuracy: 0.3262 - val_loss: 1.3396\n",
            "Epoch 9/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 398ms/step - accuracy: 0.3747 - loss: 1.3135 - val_accuracy: 0.3375 - val_loss: 1.3497\n",
            "Epoch 10/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 388ms/step - accuracy: 0.3877 - loss: 1.3124 - val_accuracy: 0.3350 - val_loss: 1.3565\n",
            "Epoch 11/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 398ms/step - accuracy: 0.4100 - loss: 1.2792 - val_accuracy: 0.3475 - val_loss: 1.3416\n",
            "Epoch 12/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 400ms/step - accuracy: 0.4017 - loss: 1.2845 - val_accuracy: 0.3175 - val_loss: 1.4086\n",
            "Epoch 13/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 395ms/step - accuracy: 0.4156 - loss: 1.2505 - val_accuracy: 0.3150 - val_loss: 1.4199\n",
            "Epoch 14/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 400ms/step - accuracy: 0.4462 - loss: 1.2203 - val_accuracy: 0.3150 - val_loss: 1.4112\n",
            "Epoch 15/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 391ms/step - accuracy: 0.4571 - loss: 1.2008 - val_accuracy: 0.3288 - val_loss: 1.4338\n",
            "Epoch 16/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 398ms/step - accuracy: 0.4795 - loss: 1.1646 - val_accuracy: 0.3288 - val_loss: 1.4747\n",
            "Epoch 17/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 439ms/step - accuracy: 0.5257 - loss: 1.1072 - val_accuracy: 0.3300 - val_loss: 1.5603\n",
            "Epoch 18/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 403ms/step - accuracy: 0.5098 - loss: 1.0962 - val_accuracy: 0.3175 - val_loss: 1.5157\n",
            "Epoch 19/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 420ms/step - accuracy: 0.5361 - loss: 1.0618 - val_accuracy: 0.3075 - val_loss: 1.5984\n",
            "Epoch 20/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 421ms/step - accuracy: 0.5685 - loss: 0.9851 - val_accuracy: 0.2975 - val_loss: 1.6027\n",
            "Epoch 21/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 413ms/step - accuracy: 0.5890 - loss: 0.9835 - val_accuracy: 0.3113 - val_loss: 1.7176\n",
            "Epoch 22/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 414ms/step - accuracy: 0.6305 - loss: 0.9176 - val_accuracy: 0.3075 - val_loss: 1.8123\n",
            "Epoch 23/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 409ms/step - accuracy: 0.6511 - loss: 0.8567 - val_accuracy: 0.3162 - val_loss: 1.8062\n",
            "Epoch 24/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 412ms/step - accuracy: 0.6780 - loss: 0.8238 - val_accuracy: 0.3388 - val_loss: 1.8328\n",
            "Epoch 25/25\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 404ms/step - accuracy: 0.6902 - loss: 0.7669 - val_accuracy: 0.3125 - val_loss: 1.9520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c8c5c24e390>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#Fitting the cnn model\n",
        "cnn.fit(\n",
        "    training_set,\n",
        "    validation_data = test_set,\n",
        "    epochs = 25,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Kj4Xxei7kX"
      },
      "source": [
        "#**Predicting the answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img(\n",
        "    '/content/drive/MyDrive/Deep_Learning/DL/CNN/dataset/single_prediction/cat_or_dog_1.jpg',\n",
        "    target_size=(64, 64)\n",
        ")\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "test_image = test_image / 255.0  # Normalization"
      ],
      "metadata": {
        "id": "FkQiwiHqeyJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cnn.predict(test_image)"
      ],
      "metadata": {
        "id": "mAEiCDUIfA0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['angry', 'happy', 'relaxed', 'sad']\n",
        "predicted_class = class_names[np.argmax(result)]"
      ],
      "metadata": {
        "id": "MWNY73sLfEup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI30nGvzO-iK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2cbf55-543b-4656-f0c0-81dc5bf5f1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "Predicted Emotion: relaxed\n"
          ]
        }
      ],
      "source": [
        "print(\"Predicted Emotion:\", predicted_class)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "J9MX_mRqjEcF",
        "HaLMUV2fjN99",
        "9VogUIo7jVrD"
      ],
      "authorship_tag": "ABX9TyN2bdmdQpCsphcnpZ99hOVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}